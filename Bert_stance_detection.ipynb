{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunalsinght/stance_detection_using_bert/blob/main/Bert_stance_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS0-GsWMFgwa",
        "outputId": "e6b459e3-1dc5-458b-b91c-c0851208acec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbPcMAUEFtIU",
        "outputId": "b3e9a69a-5e27-44eb-9bd0-62fabee874b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer,AutoModelForSequenceClassification\n",
        "\n",
        "modelName = \"distilbert-base-uncased\"\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(modelName)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    modelName,\n",
        "    num_labels=3,\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False,\n",
        "    )\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vZzZ6sZjF6iA"
      },
      "outputs": [],
      "source": [
        "#example working of tokenizer\n",
        "tokens = tokenizer.tokenize(\"Hello bert model stance\",\"Hello apple\")\n",
        "tokenIds = tokenizer.convert_tokens_to_ids(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hqKag-K_acM",
        "outputId": "f919e241-bdee-4350-8275-25134e46be09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'bert', 'model', 'stance', 'hello', 'apple']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCEnXjwL_c35",
        "outputId": "46fe10b8-7de5-4b1b-d2fa-e0e3de508a15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7592, 14324, 2944, 11032, 7592, 6207]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tokenIds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BJmKE1SM420S"
      },
      "outputs": [],
      "source": [
        "t = tokenizer(\"Hello bert model stance\",\"Hello apple\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CplUMj_j42x-",
        "outputId": "9489fc5a-c42b-4128-9a61-2bb56dee7f86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 7592, 14324, 2944, 11032, 102, 7592, 6207, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfs_1H443BX-",
        "outputId": "1973ee4a-f08f-47ce-c052-e22c9b4d960e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 7592, 1996, 14324, 2944, 11032, 102, 8038, 4095, 2045, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "t= tokenizer.encode_plus([\"Hello the bert model stance\",\"yash there\"])\n",
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "eHTIDuuOfqBm"
      },
      "outputs": [],
      "source": [
        "# import torch \n",
        "# from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rGBg_AxUgoH5"
      },
      "outputs": [],
      "source": [
        "# class StanceDataset(Dataset):\n",
        "#   def __init__(self,encodings,labels):\n",
        "#     self.encodings = encodings\n",
        "#     self.labels = labels\n",
        "\n",
        "#   def __getitem__(self,idx):\n",
        "#     item = {key: torch.tensor(val[idx]) for key,val in self.encodings.item()}\n",
        "#     item['labels']= torch.tensor(self.labels[idx])\n",
        "#     return item\n",
        "\n",
        "#   def __len__(self):\n",
        "#     return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hpgMlYX5goDF"
      },
      "outputs": [],
      "source": [
        "# def tokenize_func(data):\n",
        "#   return tokenizer(data['articleBody'],data['Headline'],padding='max_length',truncation=True,max_length=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "I4oHKXkm0X1R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kHHPxdSwoCK_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ufGl0lOhoF75",
        "outputId": "5876a70b-25f4-4b20-a1d8-dfebcc866f0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  Body ID                                        articleBody  \\\n",
              "951        34350     1873  'It's a nonsense', says official\\n\\nNorth Kore...   \n",
              "2163       22906     1331  Ottawa shooting video shown by police\\n\\nThe R...   \n",
              "2376        9179      564  The gunman in a fatal shooting that rocked Ott...   \n",
              "1632       10906      666  Homeland Security Secretary Jeh Johnson says I...   \n",
              "2718       17468     1022  A man had his genitals chopped off and thrown ...   \n",
              "9035       22102     1293  ISIS claimed Friday that a 26-year-old female ...   \n",
              "2182        2308      125  Islamic State militants and sympathisers are t...   \n",
              "1685       22532     1301  Elusive graffiti artist Banksy’s cover was blo...   \n",
              "4959       44568     2302  Online reports in jihadi and Palestinian forum...   \n",
              "2501        4013      226  WASHINGTON (AP) — U.S. airstrikes earlier this...   \n",
              "\n",
              "                                               Headline  Stance  \n",
              "951   Schoolboy almost killed by electric shock clai...       2  \n",
              "2163  That Boko Haram Ceasefire in Nigeria Isn’t A C...       2  \n",
              "2376  Viral Video Of Homeless Man Spending $100 On F...       2  \n",
              "1632  Vice's Shane Smith drops $300,000 on Vegas dinner       2  \n",
              "2718  Jordan’s King May Participate Personally In IS...       2  \n",
              "9035  Macaulay Culkin: Death claims about former chi...       2  \n",
              "2182  Non, le lancement du nouveau «Star Wars» ne se...       2  \n",
              "1685  Cameron vows to hunt down IS 'monsters' after ...       2  \n",
              "4959   Ottawa Gunman Identified As Michael Zehaf-Bibeau       2  \n",
              "2501  Obama administration DENIES congressman's clai...       2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-008167ae-9683-4d9a-8e4a-44ffab9f150e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>951</th>\n",
              "      <td>34350</td>\n",
              "      <td>1873</td>\n",
              "      <td>'It's a nonsense', says official\\n\\nNorth Kore...</td>\n",
              "      <td>Schoolboy almost killed by electric shock clai...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2163</th>\n",
              "      <td>22906</td>\n",
              "      <td>1331</td>\n",
              "      <td>Ottawa shooting video shown by police\\n\\nThe R...</td>\n",
              "      <td>That Boko Haram Ceasefire in Nigeria Isn’t A C...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2376</th>\n",
              "      <td>9179</td>\n",
              "      <td>564</td>\n",
              "      <td>The gunman in a fatal shooting that rocked Ott...</td>\n",
              "      <td>Viral Video Of Homeless Man Spending $100 On F...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1632</th>\n",
              "      <td>10906</td>\n",
              "      <td>666</td>\n",
              "      <td>Homeland Security Secretary Jeh Johnson says I...</td>\n",
              "      <td>Vice's Shane Smith drops $300,000 on Vegas dinner</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2718</th>\n",
              "      <td>17468</td>\n",
              "      <td>1022</td>\n",
              "      <td>A man had his genitals chopped off and thrown ...</td>\n",
              "      <td>Jordan’s King May Participate Personally In IS...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9035</th>\n",
              "      <td>22102</td>\n",
              "      <td>1293</td>\n",
              "      <td>ISIS claimed Friday that a 26-year-old female ...</td>\n",
              "      <td>Macaulay Culkin: Death claims about former chi...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2182</th>\n",
              "      <td>2308</td>\n",
              "      <td>125</td>\n",
              "      <td>Islamic State militants and sympathisers are t...</td>\n",
              "      <td>Non, le lancement du nouveau «Star Wars» ne se...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1685</th>\n",
              "      <td>22532</td>\n",
              "      <td>1301</td>\n",
              "      <td>Elusive graffiti artist Banksy’s cover was blo...</td>\n",
              "      <td>Cameron vows to hunt down IS 'monsters' after ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4959</th>\n",
              "      <td>44568</td>\n",
              "      <td>2302</td>\n",
              "      <td>Online reports in jihadi and Palestinian forum...</td>\n",
              "      <td>Ottawa Gunman Identified As Michael Zehaf-Bibeau</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2501</th>\n",
              "      <td>4013</td>\n",
              "      <td>226</td>\n",
              "      <td>WASHINGTON (AP) — U.S. airstrikes earlier this...</td>\n",
              "      <td>Obama administration DENIES congressman's clai...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-008167ae-9683-4d9a-8e4a-44ffab9f150e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-008167ae-9683-4d9a-8e4a-44ffab9f150e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-008167ae-9683-4d9a-8e4a-44ffab9f150e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "df = pd.read_csv('./stance_all_1_4.csv')\n",
        "df = df.sample(frac = 1)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a22Ab-splMfu",
        "outputId": "c80de024-4170-445f-a5bf-6e6f79a8c086"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "df['Stance'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gELgO-iHPLmm",
        "outputId": "78056033-8e8b-4e8c-93e4-af82e6bf35fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "txgsvPRU5rqf"
      },
      "outputs": [],
      "source": [
        "articleBodies = df.articleBody.values\n",
        "headlines = df.Headline.values\n",
        "stances = df.Stance.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d54utDD257LY",
        "outputId": "7719f01d-f738-44a3-c64d-33fb06f1545c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Headline:  Schoolboy almost killed by electric shock claims he now has superpowers like Magneto\n",
            "Article Body:  'It's a nonsense', says official\n",
            "\n",
            "North Korea has moved to deny reports its leader Kim Jong-un is planning to open a restaurant in Scotland.\n",
            "\n",
            "The dictator presides over a chain of restaurants known as “Pyongyang”, with international branches already including Amsterdam, and a number of North Korea experts had speculated that Scotland would be a natural target for expansion.\n",
            "\n",
            "Kim was reported to have taken a keen interest in Scottish affairs during the referendum debate in September, when officials claimed he felt a vote for independence “would be a very positive thing”.\n",
            "\n",
            "It has also been noted that Scotch whisky is a favourite tipple among the North Korean elite, while tourists can be asked to make gifts of the drink to tour guides and hosts instead of cash.\n",
            "\n",
            "Michael Madden, editor of the North Korea Leadership Watch blog, told the Scotsman it “would not surprise me at all if they opted to open a restaurant in Scotland”, while the UK-Korea Institute’s Jenny Town told the Mirror Kim would support “any country struggling for independence and legitimacy”.\n",
            "\n",
            "But speaking to The Independent, an official at the North Korean embassy said of the reports: “It’s a nonsense.” He declined to comment further.\n",
            "\n",
            "Mr Madden said the Pyongyang restaurants have been around for about 10 years, and that a significant proportion of their takings is funnelled back to government coffers.\n",
            "\n",
            "He said they were one of the very few ways the majority of people can experience North Korean culture without making a trip to the secretive state. “But they tailor the menus to suit,” he added. “Customers in Western Europe won’t get a plateful of dog!”\n",
            "Token IDs: tensor([  101,  2082, 11097,  2471,  2730,  2011,  3751,  5213,  4447,  2002,\n",
            "         2085,  2038,  3565, 11452,  2015,  2066, 16853,  2080,   102,  1005,\n",
            "         2009,  1005,  1055,  1037, 14652,  1005,  1010,  2758,  2880,  2167,\n",
            "         4420,  2038,  2333,  2000,  9772,  4311,  2049,  3003,  5035, 18528,\n",
            "         1011,  4895,  2003,  4041,  2000,  2330,  1037,  4825,  1999,  3885,\n",
            "         1012,  1996, 21237,  3653,  7363,  2015,  2058,  1037,  4677,  1997,\n",
            "         7884,  2124,  2004,  1523,  1052, 14001,  6292,  5654,  1524,  1010,\n",
            "         2007,  2248,  5628,  2525,  2164,  7598,  1010,  1998,  1037,  2193,\n",
            "         1997,  2167,  4420,  8519,  2018, 15520,  2008,  3885,  2052,  2022,\n",
            "         1037,  3019,  4539,  2005,  4935,  1012,  5035,  2001,  2988,  2000,\n",
            "         2031,  2579,  1037, 10326,  3037,  1999,  4104,  3821,  2076,  1996,\n",
            "         9782,  5981,  1999,  2244,  1010,  2043,  4584,  3555,  2002,  2371,\n",
            "         1037,  3789,  2005,  4336,  1523,  2052,  2022,  1037,  2200,  3893,\n",
            "         2518,  1524,  1012,  2009,  2038,  2036,  2042,  3264,  2008, 18937,\n",
            "        21265,  2003,  1037,  8837,  5955, 10814,  2426,  1996,  2167,  4759,\n",
            "         7069,  1010,  2096,  9045,  2064,  2022,  2356,  2000,  2191,  9604,\n",
            "         1997,  1996,  4392,  2000,  2778, 12468,  1998,  6184,  2612,  1997,\n",
            "         5356,  1012,  2745, 24890,  1010,  3559,  1997,  1996,  2167,  4420,\n",
            "         4105,  3422,  9927,  1010,  2409,  1996, 12196,  2386,  2009,  1523,\n",
            "         2052,  2025,  4474,  2033,  2012,  2035,  2065,  2027, 12132,  2000,\n",
            "         2330,  1037,  4825,  1999,  3885,  1524,  1010,  2096,  1996,  2866,\n",
            "         1011,  4420,  2820,  1521,  1055,  8437,  2237,  2409,  1996,  5259,\n",
            "         5035,  2052,  2490,  1523,  2151,  2406,  8084,  2005,  4336,  1998,\n",
            "        22568,  1524,  1012,  2021,  4092,  2000,  1996,  2981,  1010,  2019,\n",
            "         2880,  2012,  1996,  2167,  4759,  8408,  2056,  1997,  1996,  4311,\n",
            "         1024,  1523,  2009,  1521,  1055,   102])\n"
          ]
        }
      ],
      "source": [
        "input_ids=[]\n",
        "attention_masks=[]\n",
        "\n",
        "for i in range(len(headlines)): \n",
        "  encoded_dict=tokenizer.encode_plus(\n",
        "      [headlines[i],articleBodies[i]], #sentence to encode\n",
        "      add_special_tokens=True, #add special characters\n",
        "      max_length=256,\n",
        "      truncation=True, #add max len and truncate the sentence\n",
        "      # padding = 'max_length'\n",
        "      pad_to_max_length=True, \n",
        "      return_attention_mask=True,#construct attention mask\n",
        "      return_tensors='pt' #return pytorch tensor\n",
        "  )\n",
        "  #add encoded sentence to the list\n",
        "  input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "  # And its attention mask (simply differentiates padding from non-padding).\n",
        "  attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "stances = torch.tensor(stances)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Headline: ', headlines[0])\n",
        "print('Article Body: ',articleBodies[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "me7Z90XH57Ak"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, stances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "mIFMUsm29Y5c"
      },
      "outputs": [],
      "source": [
        "# 0.7 - training and 0.3- testing\n",
        "train_size = int(0.7*len(dataset))\n",
        "test_size = len(dataset)-train_size\n",
        "\n",
        "# splitting \n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "R9WE3Mz19Y0J"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,sampler = RandomSampler(train_dataset),batch_size = 16)\n",
        "test_dataloader = DataLoader(test_dataset,sampler = RandomSampler(test_dataset),batch_size = 16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "nxxjmf8BNi1k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6gg2Z-pX6p5",
        "outputId": "62275218-0da1-4411-9255-f31bb29e8a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  101, 18301,  3003,  ...,  1005,  1055,   102],\n",
            "        [  101, 18301,  7795,  ...,  2028,  3861,   102],\n",
            "        [  101,  8112,  1010,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 18301, 17671,  ...,     0,     0,     0],\n",
            "        [  101,  2508, 17106,  ...,  1996,  5186,   102],\n",
            "        [  101, 29584,  2003,  ...,  2010, 13878,   102]]), tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1]]), tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2])]\n"
          ]
        }
      ],
      "source": [
        "itr = iter(train_dataloader)\n",
        "data = itr.next()\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "zIdRIzJcW8jw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2726f36d-0470-43b1-dd51-9b7b5a026d49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "# optimizer \n",
        "from transformers import AdamW\n",
        "optimizer=AdamW(model.parameters(),lr=5e-5,eps=1e-8)\n",
        "epochs=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "d3icIlOZ9k9x"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm405Qnb-sHv",
        "outputId": "237df572-f513-414f-e3da-2d446e60a743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7000\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataset))\n",
        "device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFkIy1sTCH4k",
        "outputId": "c33df43d-0ae2-48e3-a886-0c407205cd14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    8902\n",
              "1     891\n",
              "0     207\n",
              "Name: Stance, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "df.Stance.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNpn85W7hnb9",
        "outputId": "d5305bf6-3f5c-4f9a-d36e-ae90d31b31cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "438"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkEzIYtJ-sEp",
        "outputId": "a4e911b4-3139-4a02-db89-be67bb88b259"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "epoch = 0 step = 0 loss = tensor(1.0212, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 1 loss = tensor(0.8613, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 2 loss = tensor(0.6819, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 3 loss = tensor(0.6800, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 4 loss = tensor(0.4901, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 5 loss = tensor(0.2907, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 6 loss = tensor(0.6052, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 7 loss = tensor(0.3023, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 8 loss = tensor(0.4524, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 9 loss = tensor(0.4198, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 10 loss = tensor(0.1143, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 11 loss = tensor(0.0963, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 12 loss = tensor(0.5973, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 13 loss = tensor(0.0760, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 14 loss = tensor(0.2705, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 15 loss = tensor(0.6953, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 16 loss = tensor(0.3887, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 17 loss = tensor(0.8635, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 18 loss = tensor(0.3668, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 19 loss = tensor(0.4414, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 20 loss = tensor(0.2391, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 21 loss = tensor(0.2671, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 22 loss = tensor(0.4135, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 23 loss = tensor(0.6840, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 24 loss = tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 25 loss = tensor(0.5185, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 26 loss = tensor(0.2405, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 27 loss = tensor(0.4023, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 28 loss = tensor(0.2601, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 29 loss = tensor(0.4175, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 30 loss = tensor(0.1341, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 31 loss = tensor(0.5038, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 32 loss = tensor(0.2607, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 33 loss = tensor(0.5130, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 34 loss = tensor(0.4286, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 35 loss = tensor(0.3624, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 36 loss = tensor(0.2373, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 37 loss = tensor(0.0884, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 38 loss = tensor(0.4270, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 39 loss = tensor(0.3898, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 40 loss = tensor(0.4438, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 41 loss = tensor(0.8694, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 42 loss = tensor(0.2345, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 43 loss = tensor(0.2429, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 44 loss = tensor(0.2804, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 45 loss = tensor(0.2381, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 46 loss = tensor(0.4970, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 47 loss = tensor(0.5037, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 48 loss = tensor(0.2315, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 49 loss = tensor(0.3827, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 50 loss = tensor(0.6377, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 51 loss = tensor(0.2201, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 52 loss = tensor(0.0943, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 53 loss = tensor(0.2653, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 54 loss = tensor(0.0717, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 55 loss = tensor(0.1915, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 56 loss = tensor(0.7380, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 57 loss = tensor(0.1970, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 58 loss = tensor(0.4017, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 59 loss = tensor(0.3696, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 60 loss = tensor(0.4427, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 61 loss = tensor(0.2743, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 62 loss = tensor(0.4082, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 63 loss = tensor(0.2725, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 64 loss = tensor(0.2642, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 65 loss = tensor(0.2851, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 66 loss = tensor(0.1810, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 67 loss = tensor(0.1942, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 68 loss = tensor(0.0861, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 69 loss = tensor(0.0419, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 70 loss = tensor(0.3923, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 71 loss = tensor(0.2821, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 72 loss = tensor(0.0353, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 73 loss = tensor(0.4828, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 74 loss = tensor(0.0309, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 75 loss = tensor(0.0705, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 76 loss = tensor(0.0230, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 77 loss = tensor(0.2555, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 78 loss = tensor(0.0447, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 79 loss = tensor(0.2727, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 80 loss = tensor(0.0557, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 81 loss = tensor(0.1262, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 82 loss = tensor(0.4708, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 83 loss = tensor(0.0838, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 84 loss = tensor(0.6329, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 85 loss = tensor(0.0149, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 86 loss = tensor(0.2837, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 87 loss = tensor(0.6987, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 88 loss = tensor(0.0808, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 89 loss = tensor(0.2799, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 90 loss = tensor(0.9351, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 91 loss = tensor(0.0338, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 92 loss = tensor(0.1055, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 93 loss = tensor(0.0280, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 94 loss = tensor(0.2886, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 95 loss = tensor(0.4703, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 96 loss = tensor(0.0448, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 97 loss = tensor(0.1637, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 98 loss = tensor(0.2386, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 99 loss = tensor(0.0383, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 100 loss = tensor(0.3373, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 101 loss = tensor(0.1643, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 102 loss = tensor(0.0629, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 103 loss = tensor(0.0542, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 104 loss = tensor(0.6306, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 105 loss = tensor(0.0130, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 106 loss = tensor(0.1231, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 107 loss = tensor(0.1864, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 108 loss = tensor(0.0523, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 109 loss = tensor(0.3966, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 110 loss = tensor(0.2981, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 111 loss = tensor(0.0363, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 112 loss = tensor(0.1936, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 113 loss = tensor(0.2092, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 114 loss = tensor(0.0266, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 115 loss = tensor(0.3156, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 116 loss = tensor(0.2463, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 117 loss = tensor(0.6556, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 118 loss = tensor(0.0816, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 119 loss = tensor(0.1727, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 120 loss = tensor(0.2605, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 121 loss = tensor(0.0564, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 122 loss = tensor(0.0289, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 123 loss = tensor(0.3466, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 124 loss = tensor(0.3563, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 125 loss = tensor(0.1809, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 126 loss = tensor(0.2450, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 127 loss = tensor(0.5467, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 128 loss = tensor(0.4786, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 129 loss = tensor(0.1995, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 130 loss = tensor(0.0208, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 131 loss = tensor(0.5835, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 132 loss = tensor(0.1969, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 133 loss = tensor(0.3620, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 134 loss = tensor(0.2270, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 135 loss = tensor(0.0329, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 136 loss = tensor(0.1606, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 137 loss = tensor(0.1094, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 138 loss = tensor(0.1692, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 139 loss = tensor(0.0494, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 140 loss = tensor(0.0098, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 141 loss = tensor(0.3827, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 142 loss = tensor(0.0233, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 143 loss = tensor(0.0084, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 144 loss = tensor(0.2001, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 145 loss = tensor(0.3424, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 146 loss = tensor(0.3755, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 147 loss = tensor(0.0570, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 148 loss = tensor(0.3167, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 149 loss = tensor(0.0079, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 150 loss = tensor(0.0083, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 151 loss = tensor(0.3247, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 152 loss = tensor(0.1511, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 153 loss = tensor(0.0367, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 154 loss = tensor(0.1636, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 155 loss = tensor(0.0222, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 156 loss = tensor(0.0338, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 157 loss = tensor(0.0099, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 158 loss = tensor(0.0656, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 159 loss = tensor(0.0396, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 160 loss = tensor(0.0236, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 161 loss = tensor(0.1443, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 162 loss = tensor(0.0564, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 163 loss = tensor(0.0379, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 164 loss = tensor(0.0574, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 165 loss = tensor(0.1698, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 166 loss = tensor(0.0218, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 167 loss = tensor(0.1816, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 168 loss = tensor(0.2050, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 169 loss = tensor(0.0154, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 170 loss = tensor(0.1902, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 171 loss = tensor(0.0509, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 172 loss = tensor(0.2351, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 173 loss = tensor(0.0319, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 174 loss = tensor(0.5289, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 175 loss = tensor(0.2476, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 176 loss = tensor(0.0287, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 177 loss = tensor(0.0186, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 178 loss = tensor(0.1479, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 179 loss = tensor(0.0280, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 180 loss = tensor(0.3831, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 181 loss = tensor(0.3156, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 182 loss = tensor(0.1960, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 183 loss = tensor(0.1840, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 184 loss = tensor(0.0103, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 185 loss = tensor(0.3736, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 186 loss = tensor(0.0061, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 187 loss = tensor(0.0352, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 188 loss = tensor(0.0198, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 189 loss = tensor(0.0915, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 190 loss = tensor(0.0214, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 191 loss = tensor(0.1734, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 192 loss = tensor(0.1343, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 193 loss = tensor(0.1411, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 194 loss = tensor(0.1862, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 195 loss = tensor(0.4701, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 196 loss = tensor(0.1250, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 197 loss = tensor(0.0290, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 198 loss = tensor(0.1753, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 199 loss = tensor(0.0319, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 200 loss = tensor(0.0088, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 201 loss = tensor(0.2873, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 202 loss = tensor(0.1980, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 203 loss = tensor(0.1495, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 204 loss = tensor(0.0577, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 205 loss = tensor(0.0317, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 206 loss = tensor(0.1494, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 207 loss = tensor(0.0579, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 208 loss = tensor(0.1359, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 209 loss = tensor(0.1316, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 210 loss = tensor(0.0273, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 211 loss = tensor(0.2433, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 212 loss = tensor(0.1728, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 213 loss = tensor(0.0251, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 214 loss = tensor(0.0206, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 215 loss = tensor(0.1711, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 216 loss = tensor(0.0433, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 217 loss = tensor(0.0186, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 218 loss = tensor(0.1800, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 219 loss = tensor(0.0267, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 220 loss = tensor(0.1376, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 221 loss = tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 222 loss = tensor(0.0489, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 223 loss = tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 224 loss = tensor(0.3795, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 225 loss = tensor(1.1430, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 226 loss = tensor(0.3040, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 227 loss = tensor(0.0244, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 228 loss = tensor(0.0113, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 229 loss = tensor(0.0154, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 230 loss = tensor(0.2123, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 231 loss = tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 232 loss = tensor(0.4386, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 233 loss = tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 234 loss = tensor(0.0347, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 235 loss = tensor(0.0363, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 236 loss = tensor(0.0142, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 237 loss = tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 238 loss = tensor(0.0118, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 239 loss = tensor(0.0259, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 240 loss = tensor(0.0094, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 241 loss = tensor(0.0109, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 242 loss = tensor(0.0125, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 243 loss = tensor(0.0243, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 244 loss = tensor(0.0153, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 245 loss = tensor(0.4202, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 246 loss = tensor(0.0093, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 247 loss = tensor(0.2108, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 248 loss = tensor(0.4305, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 249 loss = tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 250 loss = tensor(0.0082, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 251 loss = tensor(0.0119, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 252 loss = tensor(0.1980, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 253 loss = tensor(0.0094, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 254 loss = tensor(0.0065, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 255 loss = tensor(0.5661, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 256 loss = tensor(0.0056, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 257 loss = tensor(0.0112, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 258 loss = tensor(0.1959, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 259 loss = tensor(0.1994, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 260 loss = tensor(0.0806, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 261 loss = tensor(0.3528, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 262 loss = tensor(0.1119, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 263 loss = tensor(0.4401, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 264 loss = tensor(0.3394, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 265 loss = tensor(0.0920, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 266 loss = tensor(0.1439, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 267 loss = tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 268 loss = tensor(0.0126, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 269 loss = tensor(0.1376, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 270 loss = tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 271 loss = tensor(0.2105, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 272 loss = tensor(0.1234, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 273 loss = tensor(0.2196, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 274 loss = tensor(0.2824, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 275 loss = tensor(0.0226, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 276 loss = tensor(0.0209, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 277 loss = tensor(0.6042, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 278 loss = tensor(0.4601, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 279 loss = tensor(0.5522, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 280 loss = tensor(0.0110, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 281 loss = tensor(0.1161, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 282 loss = tensor(0.0585, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 283 loss = tensor(0.0112, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 284 loss = tensor(0.0540, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 285 loss = tensor(0.0060, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 286 loss = tensor(0.0062, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 287 loss = tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 288 loss = tensor(0.0319, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 289 loss = tensor(0.0305, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 290 loss = tensor(0.3373, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 291 loss = tensor(0.5482, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 292 loss = tensor(0.1219, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 293 loss = tensor(0.0788, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 294 loss = tensor(0.0215, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 295 loss = tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 296 loss = tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 297 loss = tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 298 loss = tensor(0.0308, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 299 loss = tensor(0.1556, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 300 loss = tensor(0.0536, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 301 loss = tensor(0.0268, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 302 loss = tensor(0.0384, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 303 loss = tensor(0.7267, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 304 loss = tensor(0.1420, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 305 loss = tensor(0.1315, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 306 loss = tensor(0.0953, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 307 loss = tensor(0.0085, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 308 loss = tensor(0.2046, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 309 loss = tensor(0.0233, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 310 loss = tensor(0.0227, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 311 loss = tensor(0.0058, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 312 loss = tensor(0.0188, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 313 loss = tensor(0.0246, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 314 loss = tensor(0.0212, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 315 loss = tensor(0.3415, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 316 loss = tensor(0.0611, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 317 loss = tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 318 loss = tensor(0.1487, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 319 loss = tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 320 loss = tensor(0.0338, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 321 loss = tensor(0.0205, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 322 loss = tensor(0.2313, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 323 loss = tensor(0.1587, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 324 loss = tensor(0.2048, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 325 loss = tensor(0.2623, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 326 loss = tensor(0.0391, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 327 loss = tensor(0.0329, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 328 loss = tensor(0.6066, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 329 loss = tensor(0.2678, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 330 loss = tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 331 loss = tensor(0.4309, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 332 loss = tensor(0.1544, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 333 loss = tensor(0.2248, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 334 loss = tensor(0.0356, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 335 loss = tensor(0.4104, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 336 loss = tensor(0.4039, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 337 loss = tensor(0.2116, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 338 loss = tensor(0.3134, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 339 loss = tensor(0.0240, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 340 loss = tensor(0.1650, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 341 loss = tensor(0.2107, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 342 loss = tensor(0.2936, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 343 loss = tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 344 loss = tensor(0.0202, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 345 loss = tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 346 loss = tensor(0.0189, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 347 loss = tensor(0.1987, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 348 loss = tensor(0.4573, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 349 loss = tensor(0.0538, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 350 loss = tensor(0.0935, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 351 loss = tensor(0.0568, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 352 loss = tensor(0.6500, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 353 loss = tensor(0.0598, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 354 loss = tensor(0.1151, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 355 loss = tensor(0.3018, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 356 loss = tensor(0.1760, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 357 loss = tensor(0.1605, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 358 loss = tensor(0.1400, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 359 loss = tensor(0.0177, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 360 loss = tensor(0.3428, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 361 loss = tensor(0.4177, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 362 loss = tensor(0.1458, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 363 loss = tensor(0.3339, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 364 loss = tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 365 loss = tensor(0.0229, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 366 loss = tensor(0.1003, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 367 loss = tensor(0.0359, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 368 loss = tensor(0.0203, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 369 loss = tensor(0.0206, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 370 loss = tensor(0.2687, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 371 loss = tensor(0.0496, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 372 loss = tensor(0.0443, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 373 loss = tensor(0.0714, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 374 loss = tensor(0.1126, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 375 loss = tensor(0.0380, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 376 loss = tensor(0.1949, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 377 loss = tensor(0.0960, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 378 loss = tensor(0.1531, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 379 loss = tensor(0.3069, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 380 loss = tensor(0.0435, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 381 loss = tensor(0.3170, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 382 loss = tensor(0.0538, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 383 loss = tensor(0.0698, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 384 loss = tensor(0.0268, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 385 loss = tensor(0.2118, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 386 loss = tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 387 loss = tensor(0.5938, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 388 loss = tensor(0.0335, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 389 loss = tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 390 loss = tensor(0.1363, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 391 loss = tensor(0.0191, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 392 loss = tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 393 loss = tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 394 loss = tensor(0.0190, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 395 loss = tensor(0.0399, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 396 loss = tensor(0.3746, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 397 loss = tensor(0.1370, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 398 loss = tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 399 loss = tensor(0.1864, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 400 loss = tensor(0.0182, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 401 loss = tensor(0.0334, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 402 loss = tensor(0.1356, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 403 loss = tensor(0.1649, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 404 loss = tensor(0.4029, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 405 loss = tensor(0.5871, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 406 loss = tensor(0.0252, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 407 loss = tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 408 loss = tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 409 loss = tensor(0.2095, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 410 loss = tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 411 loss = tensor(0.0382, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 412 loss = tensor(0.1361, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 413 loss = tensor(0.1405, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 414 loss = tensor(0.2262, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 415 loss = tensor(0.1375, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 416 loss = tensor(0.0382, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 417 loss = tensor(0.0190, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 418 loss = tensor(0.4197, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 419 loss = tensor(0.1565, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 420 loss = tensor(0.0358, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 421 loss = tensor(0.0182, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 422 loss = tensor(0.1241, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 423 loss = tensor(0.0322, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 424 loss = tensor(0.0149, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 425 loss = tensor(0.0337, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 426 loss = tensor(0.4999, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 427 loss = tensor(0.3511, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 428 loss = tensor(0.0190, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 429 loss = tensor(0.0292, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 430 loss = tensor(0.1319, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 431 loss = tensor(0.0561, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 432 loss = tensor(0.0215, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 433 loss = tensor(0.1252, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 434 loss = tensor(0.3963, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 435 loss = tensor(0.0244, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 436 loss = tensor(0.0131, grad_fn=<NllLossBackward0>)\n",
            "epoch = 0 step = 437 loss = tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
            "Total loss in epoch = 83.34581157629145\n",
            "avg loss in epoch 0  = 0.1902872410417613\n",
            "1\n",
            "epoch = 1 step = 0 loss = tensor(0.0297, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 1 loss = tensor(0.1454, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 2 loss = tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 3 loss = tensor(0.0152, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 4 loss = tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 5 loss = tensor(0.1278, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 6 loss = tensor(0.1622, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 7 loss = tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 8 loss = tensor(0.0402, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 9 loss = tensor(0.1348, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 10 loss = tensor(0.0275, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 11 loss = tensor(0.1185, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 12 loss = tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 13 loss = tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 14 loss = tensor(0.1285, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 15 loss = tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 16 loss = tensor(0.1446, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 17 loss = tensor(0.3666, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 18 loss = tensor(0.0286, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 19 loss = tensor(0.0327, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 20 loss = tensor(0.0294, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 21 loss = tensor(0.0152, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 22 loss = tensor(0.0414, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 23 loss = tensor(0.0313, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 24 loss = tensor(0.0137, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 25 loss = tensor(0.0243, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 26 loss = tensor(0.0275, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 27 loss = tensor(0.0153, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 28 loss = tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 29 loss = tensor(0.1427, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 30 loss = tensor(0.2756, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 31 loss = tensor(0.0191, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 32 loss = tensor(0.0086, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 33 loss = tensor(0.0097, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 34 loss = tensor(0.1507, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 35 loss = tensor(0.0163, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 36 loss = tensor(0.0247, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 37 loss = tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 38 loss = tensor(0.0069, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 39 loss = tensor(0.0059, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 40 loss = tensor(0.0143, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 41 loss = tensor(0.0062, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 42 loss = tensor(0.1732, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 43 loss = tensor(0.0065, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 44 loss = tensor(0.0189, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 45 loss = tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 46 loss = tensor(0.0185, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 47 loss = tensor(0.7712, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 48 loss = tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 49 loss = tensor(0.1736, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 50 loss = tensor(0.0108, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 51 loss = tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 52 loss = tensor(0.0144, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 53 loss = tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 54 loss = tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 55 loss = tensor(0.3396, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 56 loss = tensor(0.4443, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 57 loss = tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 58 loss = tensor(0.0077, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 59 loss = tensor(0.0135, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 60 loss = tensor(0.0094, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 61 loss = tensor(0.0298, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 62 loss = tensor(0.2673, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 63 loss = tensor(0.0185, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 64 loss = tensor(0.0125, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 65 loss = tensor(0.1836, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 66 loss = tensor(0.0312, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 67 loss = tensor(0.0196, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 68 loss = tensor(0.0126, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 69 loss = tensor(0.2795, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 70 loss = tensor(0.0079, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 71 loss = tensor(0.0085, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 72 loss = tensor(0.0100, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 73 loss = tensor(0.3673, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 74 loss = tensor(0.0077, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 75 loss = tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 76 loss = tensor(0.2552, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 77 loss = tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 78 loss = tensor(0.0085, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 79 loss = tensor(0.0100, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 80 loss = tensor(0.3272, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 81 loss = tensor(0.0230, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 82 loss = tensor(0.0074, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 83 loss = tensor(0.3528, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 84 loss = tensor(0.1737, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 85 loss = tensor(0.0069, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 86 loss = tensor(0.1717, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 87 loss = tensor(0.1821, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 88 loss = tensor(0.0072, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 89 loss = tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 90 loss = tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 91 loss = tensor(0.0108, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 92 loss = tensor(0.0207, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 93 loss = tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 94 loss = tensor(0.0183, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 95 loss = tensor(0.0089, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 96 loss = tensor(0.0085, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 97 loss = tensor(0.0278, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 98 loss = tensor(0.0229, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 99 loss = tensor(0.0077, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 100 loss = tensor(0.1538, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 101 loss = tensor(0.1536, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 102 loss = tensor(0.1295, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 103 loss = tensor(0.1486, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 104 loss = tensor(0.0498, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 105 loss = tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 106 loss = tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 107 loss = tensor(0.0116, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 108 loss = tensor(0.2484, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 109 loss = tensor(0.0234, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 110 loss = tensor(0.0133, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 111 loss = tensor(0.1683, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 112 loss = tensor(0.0573, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 113 loss = tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 114 loss = tensor(0.0106, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 115 loss = tensor(0.0305, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 116 loss = tensor(0.7573, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 117 loss = tensor(0.2962, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 118 loss = tensor(0.0096, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 119 loss = tensor(0.0223, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 120 loss = tensor(0.1238, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 121 loss = tensor(0.0412, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 122 loss = tensor(0.0226, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 123 loss = tensor(0.0175, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 124 loss = tensor(0.0170, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 125 loss = tensor(0.0184, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 126 loss = tensor(0.0188, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 127 loss = tensor(0.0154, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 128 loss = tensor(0.1598, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 129 loss = tensor(0.1496, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 130 loss = tensor(0.0364, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 131 loss = tensor(0.0159, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 132 loss = tensor(0.1703, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 133 loss = tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 134 loss = tensor(0.0079, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 135 loss = tensor(0.0076, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 136 loss = tensor(0.0167, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 137 loss = tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 138 loss = tensor(0.1625, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 139 loss = tensor(0.0217, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 140 loss = tensor(0.5030, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 141 loss = tensor(0.0073, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 142 loss = tensor(0.0103, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 143 loss = tensor(0.0111, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 144 loss = tensor(0.1685, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 145 loss = tensor(0.1429, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 146 loss = tensor(0.0097, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 147 loss = tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 148 loss = tensor(0.0375, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 149 loss = tensor(0.0114, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 150 loss = tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 151 loss = tensor(0.0112, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 152 loss = tensor(0.0221, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 153 loss = tensor(0.0126, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 154 loss = tensor(0.0231, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 155 loss = tensor(0.0114, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 156 loss = tensor(0.0099, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 157 loss = tensor(0.0190, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 158 loss = tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 159 loss = tensor(0.1958, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 160 loss = tensor(0.0319, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 161 loss = tensor(0.0166, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 162 loss = tensor(0.1638, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 163 loss = tensor(0.1320, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 164 loss = tensor(0.5382, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 165 loss = tensor(0.1693, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 166 loss = tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 167 loss = tensor(0.1282, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 168 loss = tensor(0.1484, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 169 loss = tensor(0.2474, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 170 loss = tensor(0.0245, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 171 loss = tensor(0.0135, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 172 loss = tensor(0.1209, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 173 loss = tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 174 loss = tensor(0.0132, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 175 loss = tensor(0.0104, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 176 loss = tensor(0.0151, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 177 loss = tensor(0.0525, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 178 loss = tensor(0.0137, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 179 loss = tensor(0.0132, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 180 loss = tensor(0.0454, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 181 loss = tensor(0.0433, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 182 loss = tensor(0.1254, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 183 loss = tensor(0.2097, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 184 loss = tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 185 loss = tensor(0.0132, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 186 loss = tensor(0.5448, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 187 loss = tensor(0.4346, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 188 loss = tensor(0.2730, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 189 loss = tensor(0.3087, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 190 loss = tensor(0.1512, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 191 loss = tensor(0.1017, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 192 loss = tensor(0.0147, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 193 loss = tensor(0.3302, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 194 loss = tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 195 loss = tensor(0.0185, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 196 loss = tensor(0.0515, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 197 loss = tensor(0.1500, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 198 loss = tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 199 loss = tensor(0.1513, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 200 loss = tensor(0.0165, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 201 loss = tensor(0.2469, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 202 loss = tensor(0.0199, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 203 loss = tensor(0.0202, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 204 loss = tensor(0.0314, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 205 loss = tensor(0.1127, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 206 loss = tensor(0.1767, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 207 loss = tensor(0.0160, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 208 loss = tensor(0.0176, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 209 loss = tensor(0.1026, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 210 loss = tensor(0.7102, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 211 loss = tensor(0.1321, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 212 loss = tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 213 loss = tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 214 loss = tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 215 loss = tensor(0.0773, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 216 loss = tensor(0.0715, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 217 loss = tensor(0.1074, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 218 loss = tensor(0.2250, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 219 loss = tensor(0.0983, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 220 loss = tensor(0.1512, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 221 loss = tensor(0.1199, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 222 loss = tensor(0.0222, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 223 loss = tensor(0.0192, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 224 loss = tensor(0.2677, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 225 loss = tensor(0.0172, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 226 loss = tensor(0.2936, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 227 loss = tensor(0.0778, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 228 loss = tensor(0.0560, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 229 loss = tensor(0.0602, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 230 loss = tensor(0.1403, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 231 loss = tensor(0.0284, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 232 loss = tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 233 loss = tensor(0.0166, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 234 loss = tensor(0.0328, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 235 loss = tensor(0.0142, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 236 loss = tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 237 loss = tensor(0.1224, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 238 loss = tensor(0.0130, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 239 loss = tensor(0.0127, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 240 loss = tensor(0.0216, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 241 loss = tensor(0.1955, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 242 loss = tensor(0.3058, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 243 loss = tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 244 loss = tensor(0.1405, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 245 loss = tensor(0.0100, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 246 loss = tensor(0.0108, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 247 loss = tensor(0.1774, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 248 loss = tensor(0.0267, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 249 loss = tensor(0.0225, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 250 loss = tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 251 loss = tensor(0.0208, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 252 loss = tensor(0.0362, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 253 loss = tensor(0.0097, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 254 loss = tensor(0.0078, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 255 loss = tensor(0.2857, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 256 loss = tensor(0.2718, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 257 loss = tensor(0.2164, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 258 loss = tensor(0.1381, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 259 loss = tensor(0.0161, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 260 loss = tensor(0.1600, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 261 loss = tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 262 loss = tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 263 loss = tensor(0.1446, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 264 loss = tensor(0.0388, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 265 loss = tensor(0.2350, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 266 loss = tensor(0.0227, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 267 loss = tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 268 loss = tensor(0.0114, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 269 loss = tensor(0.0200, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 270 loss = tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 271 loss = tensor(0.0104, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 272 loss = tensor(0.0225, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 273 loss = tensor(0.1913, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 274 loss = tensor(0.1322, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 275 loss = tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 276 loss = tensor(0.0118, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 277 loss = tensor(0.0113, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 278 loss = tensor(0.0736, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 279 loss = tensor(0.1320, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 280 loss = tensor(0.0126, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 281 loss = tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 282 loss = tensor(0.0138, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 283 loss = tensor(0.1328, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 284 loss = tensor(0.1523, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 285 loss = tensor(0.4037, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 286 loss = tensor(0.1255, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 287 loss = tensor(0.0117, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 288 loss = tensor(0.1160, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 289 loss = tensor(0.1388, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 290 loss = tensor(0.1276, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 291 loss = tensor(0.2481, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 292 loss = tensor(0.1190, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 293 loss = tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 294 loss = tensor(0.3355, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 295 loss = tensor(0.0177, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 296 loss = tensor(0.0222, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 297 loss = tensor(0.0247, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 298 loss = tensor(0.0425, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 299 loss = tensor(0.0423, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 300 loss = tensor(0.0607, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 301 loss = tensor(0.0217, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 302 loss = tensor(0.0186, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 303 loss = tensor(0.1063, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 304 loss = tensor(0.1166, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 305 loss = tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 306 loss = tensor(0.0457, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 307 loss = tensor(0.2580, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 308 loss = tensor(0.0164, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 309 loss = tensor(0.0368, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 310 loss = tensor(0.2736, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 311 loss = tensor(0.0182, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 312 loss = tensor(0.0336, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 313 loss = tensor(0.0865, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 314 loss = tensor(0.0444, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 315 loss = tensor(0.0418, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 316 loss = tensor(0.0258, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 317 loss = tensor(0.2128, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 318 loss = tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 319 loss = tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 320 loss = tensor(0.0351, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 321 loss = tensor(0.0124, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 322 loss = tensor(0.1755, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 323 loss = tensor(0.1295, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 324 loss = tensor(0.2922, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 325 loss = tensor(0.5035, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 326 loss = tensor(0.1349, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 327 loss = tensor(0.1083, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 328 loss = tensor(0.1069, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 329 loss = tensor(0.1375, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 330 loss = tensor(0.0126, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 331 loss = tensor(0.1077, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 332 loss = tensor(0.0360, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 333 loss = tensor(0.1410, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 334 loss = tensor(0.0644, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 335 loss = tensor(0.1137, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 336 loss = tensor(0.0191, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 337 loss = tensor(0.1454, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 338 loss = tensor(0.5473, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 339 loss = tensor(0.2963, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 340 loss = tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 341 loss = tensor(0.1453, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 342 loss = tensor(0.0233, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 343 loss = tensor(0.5592, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 344 loss = tensor(0.0392, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 345 loss = tensor(0.5658, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 346 loss = tensor(0.1831, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 347 loss = tensor(0.1332, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 348 loss = tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 349 loss = tensor(0.0348, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 350 loss = tensor(0.0570, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 351 loss = tensor(0.0352, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 352 loss = tensor(0.1277, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 353 loss = tensor(0.1104, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 354 loss = tensor(0.0314, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 355 loss = tensor(0.4197, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 356 loss = tensor(0.0569, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 357 loss = tensor(0.2908, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 358 loss = tensor(0.0274, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 359 loss = tensor(0.0614, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 360 loss = tensor(0.1355, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 361 loss = tensor(0.0177, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 362 loss = tensor(0.0574, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 363 loss = tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 364 loss = tensor(0.3808, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 365 loss = tensor(0.0140, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 366 loss = tensor(0.1441, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 367 loss = tensor(0.1257, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 368 loss = tensor(0.1281, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 369 loss = tensor(0.2928, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 370 loss = tensor(0.0280, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 371 loss = tensor(0.1305, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 372 loss = tensor(0.0171, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 373 loss = tensor(0.2662, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 374 loss = tensor(0.0160, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 375 loss = tensor(0.0118, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 376 loss = tensor(0.0538, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 377 loss = tensor(0.0221, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 378 loss = tensor(0.0224, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 379 loss = tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 380 loss = tensor(0.1153, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 381 loss = tensor(0.0122, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 382 loss = tensor(0.0128, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 383 loss = tensor(0.0355, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 384 loss = tensor(0.3496, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 385 loss = tensor(0.0122, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 386 loss = tensor(0.1307, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 387 loss = tensor(0.0107, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 388 loss = tensor(0.0282, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 389 loss = tensor(0.0109, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 390 loss = tensor(0.1317, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 391 loss = tensor(0.2825, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 392 loss = tensor(0.1173, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 393 loss = tensor(0.5801, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 394 loss = tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 395 loss = tensor(0.0113, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 396 loss = tensor(0.0218, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 397 loss = tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 398 loss = tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 399 loss = tensor(0.1497, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 400 loss = tensor(0.1768, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 401 loss = tensor(0.1328, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 402 loss = tensor(0.0419, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 403 loss = tensor(0.0201, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 404 loss = tensor(0.0319, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 405 loss = tensor(0.5484, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 406 loss = tensor(0.1253, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 407 loss = tensor(0.1285, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 408 loss = tensor(0.3066, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 409 loss = tensor(0.0243, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 410 loss = tensor(0.4643, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 411 loss = tensor(0.0283, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 412 loss = tensor(0.0165, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 413 loss = tensor(0.0154, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 414 loss = tensor(0.2768, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 415 loss = tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 416 loss = tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 417 loss = tensor(0.1261, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 418 loss = tensor(0.0474, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 419 loss = tensor(0.0187, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 420 loss = tensor(0.1274, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 421 loss = tensor(0.4781, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 422 loss = tensor(0.5908, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 423 loss = tensor(0.0158, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 424 loss = tensor(0.0619, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 425 loss = tensor(0.1367, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 426 loss = tensor(0.0079, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 427 loss = tensor(0.0393, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 428 loss = tensor(0.0291, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 429 loss = tensor(0.0144, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 430 loss = tensor(0.2088, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 431 loss = tensor(0.3393, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 432 loss = tensor(0.1404, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 433 loss = tensor(0.0373, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 434 loss = tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 435 loss = tensor(0.0322, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 436 loss = tensor(0.1375, grad_fn=<NllLossBackward0>)\n",
            "epoch = 1 step = 437 loss = tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
            "Total loss in epoch = 41.796954385907156\n",
            "avg loss in epoch 1  = 0.09542683649750493\n"
          ]
        }
      ],
      "source": [
        "for epoch_i in range(0,epochs):\n",
        "  model.train()\n",
        "  print(epoch_i)\n",
        "  # print(len(train_dataloader))\n",
        "  epoch_loss = 0\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    # print(b_labels)\n",
        "    print(\"epoch =\",epoch_i,\"step =\",step,end=\" \")\n",
        "    model.zero_grad() \n",
        "    output = model(b_input_ids, \n",
        "                            #  token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "    print(\"loss =\",output.loss)\n",
        "    epoch_loss += output.loss.item()\n",
        "    output.loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "  print(\"Total loss in epoch =\",epoch_loss)\n",
        "  print(\"avg loss in epoch\",epoch_i,\" =\",epoch_loss/len(train_dataloader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "FBgMomTUJNjx"
      },
      "outputs": [],
      "source": [
        "save_directory = 'saved'\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "model.save_pretrained(save_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "9L8vWaWZNNrm"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "model_save_name=\"bert-stance-model.pt\"\n",
        "path = f'/content/gdrive/My Drive/{model_save_name}'\n",
        "torch.save(model.state_dict(),path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "HUhzEt20FB6t"
      },
      "outputs": [],
      "source": [
        "#Define a helper function for calculating accuracy.\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def validation_accuracy(orig, pred):\n",
        "  correct = 0\n",
        "  agree_correct=0\n",
        "  disagree_correct=0\n",
        "  unrelated_correct=0\n",
        "  total_agree=0\n",
        "  total_disagree=0\n",
        "  total_unrelated=0\n",
        "  for i in range(len(orig)):\n",
        "    if orig[i]==pred[i]:\n",
        "      correct+=1\n",
        "    if orig[i]==1:\n",
        "      total_agree+=1\n",
        "      if pred[i]==1:\n",
        "        agree_correct+=1\n",
        "    if orig[i]==0:\n",
        "      total_disagree+=1\n",
        "      if pred[i]==0:\n",
        "        disagree_correct+=1 \n",
        "    if orig[i]==2:\n",
        "      total_unrelated+=1\n",
        "      if pred[i]==2:\n",
        "        unrelated_correct+=1\n",
        "\n",
        "  if total_agree==0:\n",
        "    agree_acc = 1\n",
        "  else:\n",
        "    agree_acc = agree_correct/total_agree\n",
        "\n",
        "  if total_disagree==0:\n",
        "    disagree_acc=1\n",
        "  else:\n",
        "    disagree_acc = disagree_correct/total_disagree\n",
        "\n",
        "  if total_unrelated==0:\n",
        "    unrelated_acc=1\n",
        "  else:\n",
        "    unrelated_acc = unrelated_correct/total_unrelated\n",
        "  return [correct/len(orig),agree_acc,disagree_acc,total_agree,total_disagree,unrelated_acc,total_unrelated]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "PM9sDaKIFPul"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p10RsMaA7Il",
        "outputId": "35831c6c-0b17-4944-9afd-ed7472c3af4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 0\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 1  = 1.0\n",
            "loss = 0.011744881980121136\n",
            "\n",
            "\n",
            "step = 1\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2])\n",
            "Accuracy for batch 2  = 1.0\n",
            "loss = 0.022237958386540413\n",
            "\n",
            "\n",
            "step = 2\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 3  = 1.0\n",
            "loss = 0.0011289078975096345\n",
            "\n",
            "\n",
            "step = 3\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 1])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1])\n",
            "Accuracy for batch 4  = 0.9375\n",
            "loss = 0.13522794842720032\n",
            "\n",
            "\n",
            "step = 4\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 5  = 1.0\n",
            "loss = 0.010798913426697254\n",
            "\n",
            "\n",
            "step = 5\n",
            "original labels = tensor([1, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 6  = 0.9375\n",
            "loss = 0.14175991714000702\n",
            "\n",
            "\n",
            "step = 6\n",
            "original labels = tensor([2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 7  = 1.0\n",
            "loss = 0.02107350341975689\n",
            "\n",
            "\n",
            "step = 7\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 8  = 1.0\n",
            "loss = 0.023945948109030724\n",
            "\n",
            "\n",
            "step = 8\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2])\n",
            "Accuracy for batch 9  = 1.0\n",
            "loss = 0.021510696038603783\n",
            "\n",
            "\n",
            "step = 9\n",
            "original labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "Accuracy for batch 10  = 1.0\n",
            "loss = 0.02129187248647213\n",
            "\n",
            "\n",
            "step = 10\n",
            "original labels = tensor([2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 11  = 0.9375\n",
            "loss = 0.12924684584140778\n",
            "\n",
            "\n",
            "step = 11\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2])\n",
            "Accuracy for batch 12  = 0.9375\n",
            "loss = 0.12111266702413559\n",
            "\n",
            "\n",
            "step = 12\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 13  = 1.0\n",
            "loss = 0.0019038874888792634\n",
            "\n",
            "\n",
            "step = 13\n",
            "original labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 14  = 1.0\n",
            "loss = 0.011279033496975899\n",
            "\n",
            "\n",
            "step = 14\n",
            "original labels = tensor([1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 15  = 1.0\n",
            "loss = 0.05833785980939865\n",
            "\n",
            "\n",
            "step = 15\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 16  = 1.0\n",
            "loss = 0.0007448879769071937\n",
            "\n",
            "\n",
            "step = 16\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 17  = 1.0\n",
            "loss = 0.0005718529573641717\n",
            "\n",
            "\n",
            "step = 17\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2])\n",
            "Accuracy for batch 18  = 1.0\n",
            "loss = 0.03178875893354416\n",
            "\n",
            "\n",
            "step = 18\n",
            "original labels = tensor([1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 19  = 0.9375\n",
            "loss = 0.09649286419153214\n",
            "\n",
            "\n",
            "step = 19\n",
            "original labels = tensor([2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "Accuracy for batch 20  = 1.0\n",
            "loss = 0.021058011800050735\n",
            "\n",
            "\n",
            "step = 20\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 21  = 0.9375\n",
            "loss = 0.5445401668548584\n",
            "\n",
            "\n",
            "step = 21\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 22  = 1.0\n",
            "loss = 0.000570311676710844\n",
            "\n",
            "\n",
            "step = 22\n",
            "original labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 23  = 1.0\n",
            "loss = 0.030905162915587425\n",
            "\n",
            "\n",
            "step = 23\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 24  = 1.0\n",
            "loss = 0.00043397414265200496\n",
            "\n",
            "\n",
            "step = 24\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
            "Accuracy for batch 25  = 0.9375\n",
            "loss = 0.4480315148830414\n",
            "\n",
            "\n",
            "step = 25\n",
            "original labels = tensor([2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 26  = 1.0\n",
            "loss = 0.02186460979282856\n",
            "\n",
            "\n",
            "step = 26\n",
            "original labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 27  = 1.0\n",
            "loss = 0.010977346450090408\n",
            "\n",
            "\n",
            "step = 27\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2])\n",
            "Accuracy for batch 28  = 1.0\n",
            "loss = 0.021396808326244354\n",
            "\n",
            "\n",
            "step = 28\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
            "Accuracy for batch 29  = 0.9375\n",
            "loss = 0.1509065330028534\n",
            "\n",
            "\n",
            "step = 29\n",
            "original labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2])\n",
            "Accuracy for batch 30  = 0.9375\n",
            "loss = 0.29600557684898376\n",
            "\n",
            "\n",
            "step = 30\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0])\n",
            "labels = tensor([2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1])\n",
            "Accuracy for batch 31  = 0.875\n",
            "loss = 0.3644697368144989\n",
            "\n",
            "\n",
            "step = 31\n",
            "original labels = tensor([2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2])\n",
            "Accuracy for batch 32  = 0.9375\n",
            "loss = 0.15628883242607117\n",
            "\n",
            "\n",
            "step = 32\n",
            "original labels = tensor([2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2])\n",
            "Accuracy for batch 33  = 0.9375\n",
            "loss = 0.12968266010284424\n",
            "\n",
            "\n",
            "step = 33\n",
            "original labels = tensor([2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 34  = 0.9375\n",
            "loss = 0.3209565281867981\n",
            "\n",
            "\n",
            "step = 34\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 35  = 1.0\n",
            "loss = 0.009086411446332932\n",
            "\n",
            "\n",
            "step = 35\n",
            "original labels = tensor([2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "Accuracy for batch 36  = 0.9375\n",
            "loss = 0.1283869594335556\n",
            "\n",
            "\n",
            "step = 36\n",
            "original labels = tensor([1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "labels = tensor([1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "Accuracy for batch 37  = 1.0\n",
            "loss = 0.03163179010152817\n",
            "\n",
            "\n",
            "step = 37\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2])\n",
            "Accuracy for batch 38  = 1.0\n",
            "loss = 0.028603287413716316\n",
            "\n",
            "\n",
            "step = 38\n",
            "original labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 39  = 1.0\n",
            "loss = 0.010996238328516483\n",
            "\n",
            "\n",
            "step = 39\n",
            "original labels = tensor([1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 1])\n",
            "labels = tensor([1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1])\n",
            "Accuracy for batch 40  = 0.9375\n",
            "loss = 0.15225979685783386\n",
            "\n",
            "\n",
            "step = 40\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 41  = 1.0\n",
            "loss = 0.010731612332165241\n",
            "\n",
            "\n",
            "step = 41\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2])\n",
            "Accuracy for batch 42  = 0.875\n",
            "loss = 0.25049635767936707\n",
            "\n",
            "\n",
            "step = 42\n",
            "original labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 43  = 1.0\n",
            "loss = 0.02275635302066803\n",
            "\n",
            "\n",
            "step = 43\n",
            "original labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 44  = 1.0\n",
            "loss = 0.011099910363554955\n",
            "\n",
            "\n",
            "step = 44\n",
            "original labels = tensor([2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 45  = 1.0\n",
            "loss = 0.0213999655097723\n",
            "\n",
            "\n",
            "step = 45\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 46  = 1.0\n",
            "loss = 0.0011499112006276846\n",
            "\n",
            "\n",
            "step = 46\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 47  = 1.0\n",
            "loss = 0.02126469649374485\n",
            "\n",
            "\n",
            "step = 47\n",
            "original labels = tensor([2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 48  = 0.9375\n",
            "loss = 0.48008662462234497\n",
            "\n",
            "\n",
            "step = 48\n",
            "original labels = tensor([1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 49  = 1.0\n",
            "loss = 0.021273033693432808\n",
            "\n",
            "\n",
            "step = 49\n",
            "original labels = tensor([2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2])\n",
            "Accuracy for batch 50  = 1.0\n",
            "loss = 0.04280246049165726\n",
            "\n",
            "\n",
            "step = 50\n",
            "original labels = tensor([2, 2, 1, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 51  = 0.9375\n",
            "loss = 0.14180369675159454\n",
            "\n",
            "\n",
            "step = 51\n",
            "original labels = tensor([1, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2])\n",
            "labels = tensor([1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2])\n",
            "Accuracy for batch 52  = 0.875\n",
            "loss = 0.27039414644241333\n",
            "\n",
            "\n",
            "step = 52\n",
            "original labels = tensor([2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2])\n",
            "labels = tensor([2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 53  = 0.875\n",
            "loss = 0.19787700474262238\n",
            "\n",
            "\n",
            "step = 53\n",
            "original labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 54  = 1.0\n",
            "loss = 0.011164281517267227\n",
            "\n",
            "\n",
            "step = 54\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "Accuracy for batch 55  = 0.9375\n",
            "loss = 0.13058152794837952\n",
            "\n",
            "\n",
            "step = 55\n",
            "original labels = tensor([1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 56  = 1.0\n",
            "loss = 0.021640116348862648\n",
            "\n",
            "\n",
            "step = 56\n",
            "original labels = tensor([2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0])\n",
            "labels = tensor([2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1])\n",
            "Accuracy for batch 57  = 0.9375\n",
            "loss = 0.14075079560279846\n",
            "\n",
            "\n",
            "step = 57\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 58  = 1.0\n",
            "loss = 0.0008706302032805979\n",
            "\n",
            "\n",
            "step = 58\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 59  = 0.9375\n",
            "loss = 0.13034690916538239\n",
            "\n",
            "\n",
            "step = 59\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 60  = 0.9375\n",
            "loss = 0.3046739399433136\n",
            "\n",
            "\n",
            "step = 60\n",
            "original labels = tensor([2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 61  = 1.0\n",
            "loss = 0.031681377440690994\n",
            "\n",
            "\n",
            "step = 61\n",
            "original labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 62  = 1.0\n",
            "loss = 0.021230708807706833\n",
            "\n",
            "\n",
            "step = 62\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 63  = 1.0\n",
            "loss = 0.0009247083216905594\n",
            "\n",
            "\n",
            "step = 63\n",
            "original labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 64  = 0.9375\n",
            "loss = 0.1817188858985901\n",
            "\n",
            "\n",
            "step = 64\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 65  = 1.0\n",
            "loss = 0.0004322692984715104\n",
            "\n",
            "\n",
            "step = 65\n",
            "original labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 66  = 1.0\n",
            "loss = 0.010963192209601402\n",
            "\n",
            "\n",
            "step = 66\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2])\n",
            "Accuracy for batch 67  = 0.8125\n",
            "loss = 0.42641690373420715\n",
            "\n",
            "\n",
            "step = 67\n",
            "original labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 68  = 1.0\n",
            "loss = 0.010852361097931862\n",
            "\n",
            "\n",
            "step = 68\n",
            "original labels = tensor([1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 69  = 1.0\n",
            "loss = 0.022131573408842087\n",
            "\n",
            "\n",
            "step = 69\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 70  = 0.9375\n",
            "loss = 0.13739462196826935\n",
            "\n",
            "\n",
            "step = 70\n",
            "original labels = tensor([2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 71  = 1.0\n",
            "loss = 0.033924851566553116\n",
            "\n",
            "\n",
            "step = 71\n",
            "original labels = tensor([2, 1, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2])\n",
            "labels = tensor([2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2])\n",
            "Accuracy for batch 72  = 0.875\n",
            "loss = 0.2724493741989136\n",
            "\n",
            "\n",
            "step = 72\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "Accuracy for batch 73  = 0.9375\n",
            "loss = 0.3601769506931305\n",
            "\n",
            "\n",
            "step = 73\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 74  = 1.0\n",
            "loss = 0.010704761371016502\n",
            "\n",
            "\n",
            "step = 74\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 75  = 1.0\n",
            "loss = 0.012532494962215424\n",
            "\n",
            "\n",
            "step = 75\n",
            "original labels = tensor([2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 76  = 1.0\n",
            "loss = 0.01099454890936613\n",
            "\n",
            "\n",
            "step = 76\n",
            "original labels = tensor([2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1])\n",
            "labels = tensor([2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1])\n",
            "Accuracy for batch 77  = 0.9375\n",
            "loss = 0.1518932431936264\n",
            "\n",
            "\n",
            "step = 77\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 78  = 1.0\n",
            "loss = 0.011102319695055485\n",
            "\n",
            "\n",
            "step = 78\n",
            "original labels = tensor([1, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 79  = 0.9375\n",
            "loss = 0.13826322555541992\n",
            "\n",
            "\n",
            "step = 79\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 80  = 1.0\n",
            "loss = 0.013173487037420273\n",
            "\n",
            "\n",
            "step = 80\n",
            "original labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 81  = 1.0\n",
            "loss = 0.01172962412238121\n",
            "\n",
            "\n",
            "step = 81\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "Accuracy for batch 82  = 1.0\n",
            "loss = 0.02116077020764351\n",
            "\n",
            "\n",
            "step = 82\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 83  = 1.0\n",
            "loss = 0.0007981015951372683\n",
            "\n",
            "\n",
            "step = 83\n",
            "original labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 84  = 1.0\n",
            "loss = 0.022333649918437004\n",
            "\n",
            "\n",
            "step = 84\n",
            "original labels = tensor([2, 2, 0, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2])\n",
            "labels = tensor([2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2])\n",
            "Accuracy for batch 85  = 0.9375\n",
            "loss = 0.16341754794120789\n",
            "\n",
            "\n",
            "step = 85\n",
            "original labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 86  = 1.0\n",
            "loss = 0.021650081500411034\n",
            "\n",
            "\n",
            "step = 86\n",
            "original labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 87  = 1.0\n",
            "loss = 0.021091219037771225\n",
            "\n",
            "\n",
            "step = 87\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
            "Accuracy for batch 88  = 1.0\n",
            "loss = 0.03273986652493477\n",
            "\n",
            "\n",
            "step = 88\n",
            "original labels = tensor([2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 89  = 0.9375\n",
            "loss = 0.11984652280807495\n",
            "\n",
            "\n",
            "step = 89\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 90  = 0.9375\n",
            "loss = 0.22748109698295593\n",
            "\n",
            "\n",
            "step = 90\n",
            "original labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 91  = 1.0\n",
            "loss = 0.01081798318773508\n",
            "\n",
            "\n",
            "step = 91\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
            "Accuracy for batch 92  = 0.875\n",
            "loss = 0.48323145508766174\n",
            "\n",
            "\n",
            "step = 92\n",
            "original labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1])\n",
            "labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1])\n",
            "Accuracy for batch 93  = 1.0\n",
            "loss = 0.04499097168445587\n",
            "\n",
            "\n",
            "step = 93\n",
            "original labels = tensor([1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 94  = 0.9375\n",
            "loss = 0.11556074768304825\n",
            "\n",
            "\n",
            "step = 94\n",
            "original labels = tensor([2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "Accuracy for batch 95  = 1.0\n",
            "loss = 0.031201060861349106\n",
            "\n",
            "\n",
            "step = 95\n",
            "original labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 96  = 1.0\n",
            "loss = 0.010708938352763653\n",
            "\n",
            "\n",
            "step = 96\n",
            "original labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1])\n",
            "labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1])\n",
            "Accuracy for batch 97  = 1.0\n",
            "loss = 0.03219199553132057\n",
            "\n",
            "\n",
            "step = 97\n",
            "original labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 98  = 0.875\n",
            "loss = 0.25175586342811584\n",
            "\n",
            "\n",
            "step = 98\n",
            "original labels = tensor([0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 99  = 0.875\n",
            "loss = 0.2513278126716614\n",
            "\n",
            "\n",
            "step = 99\n",
            "original labels = tensor([2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 100  = 0.9375\n",
            "loss = 0.13004504144191742\n",
            "\n",
            "\n",
            "step = 100\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "Accuracy for batch 101  = 1.0\n",
            "loss = 0.011554830707609653\n",
            "\n",
            "\n",
            "step = 101\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1])\n",
            "Accuracy for batch 102  = 1.0\n",
            "loss = 0.021301422268152237\n",
            "\n",
            "\n",
            "step = 102\n",
            "original labels = tensor([1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 103  = 1.0\n",
            "loss = 0.02132011391222477\n",
            "\n",
            "\n",
            "step = 103\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "Accuracy for batch 104  = 1.0\n",
            "loss = 0.011154396459460258\n",
            "\n",
            "\n",
            "step = 104\n",
            "original labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2])\n",
            "labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2])\n",
            "Accuracy for batch 105  = 1.0\n",
            "loss = 0.03261259198188782\n",
            "\n",
            "\n",
            "step = 105\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "Accuracy for batch 106  = 0.9375\n",
            "loss = 0.12101849913597107\n",
            "\n",
            "\n",
            "step = 106\n",
            "original labels = tensor([2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 107  = 0.9375\n",
            "loss = 0.5537988543510437\n",
            "\n",
            "\n",
            "step = 107\n",
            "original labels = tensor([2, 1, 2, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "labels = tensor([2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 108  = 0.9375\n",
            "loss = 0.16115275025367737\n",
            "\n",
            "\n",
            "step = 108\n",
            "original labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 109  = 1.0\n",
            "loss = 0.010802805423736572\n",
            "\n",
            "\n",
            "step = 109\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "Accuracy for batch 110  = 1.0\n",
            "loss = 0.010898894630372524\n",
            "\n",
            "\n",
            "step = 110\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2])\n",
            "Accuracy for batch 111  = 1.0\n",
            "loss = 0.021512791514396667\n",
            "\n",
            "\n",
            "step = 111\n",
            "original labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2])\n",
            "labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2])\n",
            "Accuracy for batch 112  = 1.0\n",
            "loss = 0.034321028739213943\n",
            "\n",
            "\n",
            "step = 112\n",
            "original labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "Accuracy for batch 113  = 1.0\n",
            "loss = 0.026482868939638138\n",
            "\n",
            "\n",
            "step = 113\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 114  = 1.0\n",
            "loss = 0.021124839782714844\n",
            "\n",
            "\n",
            "step = 114\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
            "Accuracy for batch 115  = 1.0\n",
            "loss = 0.011550188064575195\n",
            "\n",
            "\n",
            "step = 115\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2])\n",
            "Accuracy for batch 116  = 1.0\n",
            "loss = 0.010825603269040585\n",
            "\n",
            "\n",
            "step = 116\n",
            "original labels = tensor([2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 117  = 0.9375\n",
            "loss = 0.13244755566120148\n",
            "\n",
            "\n",
            "step = 117\n",
            "original labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 118  = 1.0\n",
            "loss = 0.011104829609394073\n",
            "\n",
            "\n",
            "step = 118\n",
            "original labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1])\n",
            "labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1])\n",
            "Accuracy for batch 119  = 1.0\n",
            "loss = 0.03232589364051819\n",
            "\n",
            "\n",
            "step = 119\n",
            "original labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 120  = 1.0\n",
            "loss = 0.012136412784457207\n",
            "\n",
            "\n",
            "step = 120\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 121  = 1.0\n",
            "loss = 0.0005102753057144582\n",
            "\n",
            "\n",
            "step = 121\n",
            "original labels = tensor([2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 122  = 1.0\n",
            "loss = 0.02164100483059883\n",
            "\n",
            "\n",
            "step = 122\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 123  = 1.0\n",
            "loss = 0.01103875134140253\n",
            "\n",
            "\n",
            "step = 123\n",
            "original labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 124  = 1.0\n",
            "loss = 0.03854089975357056\n",
            "\n",
            "\n",
            "step = 124\n",
            "original labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2])\n",
            "Accuracy for batch 125  = 1.0\n",
            "loss = 0.02139369212090969\n",
            "\n",
            "\n",
            "step = 125\n",
            "original labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 126  = 1.0\n",
            "loss = 0.01087102945894003\n",
            "\n",
            "\n",
            "step = 126\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 127  = 1.0\n",
            "loss = 0.0113145736977458\n",
            "\n",
            "\n",
            "step = 127\n",
            "original labels = tensor([2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
            "labels = tensor([2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
            "Accuracy for batch 128  = 1.0\n",
            "loss = 0.051837075501680374\n",
            "\n",
            "\n",
            "step = 128\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1])\n",
            "Accuracy for batch 129  = 1.0\n",
            "loss = 0.03561989217996597\n",
            "\n",
            "\n",
            "step = 129\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2])\n",
            "Accuracy for batch 130  = 0.875\n",
            "loss = 0.3442627191543579\n",
            "\n",
            "\n",
            "step = 130\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 131  = 1.0\n",
            "loss = 0.010902656242251396\n",
            "\n",
            "\n",
            "step = 131\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 1, 2, 1, 0, 2, 1, 1, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2])\n",
            "Accuracy for batch 132  = 0.875\n",
            "loss = 0.6096071600914001\n",
            "\n",
            "\n",
            "step = 132\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2])\n",
            "Accuracy for batch 133  = 1.0\n",
            "loss = 0.03340659663081169\n",
            "\n",
            "\n",
            "step = 133\n",
            "original labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2])\n",
            "Accuracy for batch 134  = 0.9375\n",
            "loss = 0.12985306978225708\n",
            "\n",
            "\n",
            "step = 134\n",
            "original labels = tensor([2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 135  = 0.9375\n",
            "loss = 0.36625710129737854\n",
            "\n",
            "\n",
            "step = 135\n",
            "original labels = tensor([2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2])\n",
            "labels = tensor([2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "Accuracy for batch 136  = 0.9375\n",
            "loss = 0.16094915568828583\n",
            "\n",
            "\n",
            "step = 136\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 137  = 1.0\n",
            "loss = 0.0004942133091390133\n",
            "\n",
            "\n",
            "step = 137\n",
            "original labels = tensor([2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2])\n",
            "Accuracy for batch 138  = 1.0\n",
            "loss = 0.041554044932127\n",
            "\n",
            "\n",
            "step = 138\n",
            "original labels = tensor([2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 139  = 1.0\n",
            "loss = 0.021183010190725327\n",
            "\n",
            "\n",
            "step = 139\n",
            "original labels = tensor([2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 140  = 0.9375\n",
            "loss = 0.12791872024536133\n",
            "\n",
            "\n",
            "step = 140\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 141  = 1.0\n",
            "loss = 0.0013417107984423637\n",
            "\n",
            "\n",
            "step = 141\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 142  = 1.0\n",
            "loss = 0.011250504292547703\n",
            "\n",
            "\n",
            "step = 142\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "Accuracy for batch 143  = 0.9375\n",
            "loss = 0.12093035131692886\n",
            "\n",
            "\n",
            "step = 143\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2])\n",
            "Accuracy for batch 144  = 1.0\n",
            "loss = 0.03502403572201729\n",
            "\n",
            "\n",
            "step = 144\n",
            "original labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 145  = 1.0\n",
            "loss = 0.021420296281576157\n",
            "\n",
            "\n",
            "step = 145\n",
            "original labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 146  = 1.0\n",
            "loss = 0.021625246852636337\n",
            "\n",
            "\n",
            "step = 146\n",
            "original labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2])\n",
            "Accuracy for batch 147  = 0.9375\n",
            "loss = 0.3117900788784027\n",
            "\n",
            "\n",
            "step = 147\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2])\n",
            "Accuracy for batch 148  = 0.875\n",
            "loss = 0.2893034517765045\n",
            "\n",
            "\n",
            "step = 148\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 149  = 1.0\n",
            "loss = 0.011234709061682224\n",
            "\n",
            "\n",
            "step = 149\n",
            "original labels = tensor([2, 2, 2, 0, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 150  = 0.8125\n",
            "loss = 0.5776700973510742\n",
            "\n",
            "\n",
            "step = 150\n",
            "original labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 151  = 1.0\n",
            "loss = 0.01254209689795971\n",
            "\n",
            "\n",
            "step = 151\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 152  = 1.0\n",
            "loss = 0.0008910638862289488\n",
            "\n",
            "\n",
            "step = 152\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "Accuracy for batch 153  = 1.0\n",
            "loss = 0.011337117291986942\n",
            "\n",
            "\n",
            "step = 153\n",
            "original labels = tensor([1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2])\n",
            "labels = tensor([1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 154  = 0.9375\n",
            "loss = 0.27383652329444885\n",
            "\n",
            "\n",
            "step = 154\n",
            "original labels = tensor([2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
            "labels = tensor([2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
            "Accuracy for batch 155  = 0.9375\n",
            "loss = 0.1337137222290039\n",
            "\n",
            "\n",
            "step = 155\n",
            "original labels = tensor([2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 156  = 0.9375\n",
            "loss = 0.143894761800766\n",
            "\n",
            "\n",
            "step = 156\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 157  = 1.0\n",
            "loss = 0.0006760908290743828\n",
            "\n",
            "\n",
            "step = 157\n",
            "original labels = tensor([0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 158  = 0.875\n",
            "loss = 0.23874372243881226\n",
            "\n",
            "\n",
            "step = 158\n",
            "original labels = tensor([2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 159  = 1.0\n",
            "loss = 0.021181443706154823\n",
            "\n",
            "\n",
            "step = 159\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 160  = 1.0\n",
            "loss = 0.0006913648103363812\n",
            "\n",
            "\n",
            "step = 160\n",
            "original labels = tensor([2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 161  = 1.0\n",
            "loss = 0.02155931480228901\n",
            "\n",
            "\n",
            "step = 161\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2])\n",
            "Accuracy for batch 162  = 0.9375\n",
            "loss = 0.1318439394235611\n",
            "\n",
            "\n",
            "step = 162\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2])\n",
            "Accuracy for batch 163  = 1.0\n",
            "loss = 0.010791072621941566\n",
            "\n",
            "\n",
            "step = 163\n",
            "original labels = tensor([2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2])\n",
            "labels = tensor([2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "Accuracy for batch 164  = 0.9375\n",
            "loss = 0.14068445563316345\n",
            "\n",
            "\n",
            "step = 164\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 165  = 1.0\n",
            "loss = 0.012042408809065819\n",
            "\n",
            "\n",
            "step = 165\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 166  = 1.0\n",
            "loss = 0.0010279548587277532\n",
            "\n",
            "\n",
            "step = 166\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 1, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 167  = 0.9375\n",
            "loss = 0.5281230807304382\n",
            "\n",
            "\n",
            "step = 167\n",
            "original labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "Accuracy for batch 168  = 1.0\n",
            "loss = 0.022591955959796906\n",
            "\n",
            "\n",
            "step = 168\n",
            "original labels = tensor([2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 169  = 1.0\n",
            "loss = 0.031574126332998276\n",
            "\n",
            "\n",
            "step = 169\n",
            "original labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1])\n",
            "labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1])\n",
            "Accuracy for batch 170  = 1.0\n",
            "loss = 0.055055949836969376\n",
            "\n",
            "\n",
            "step = 170\n",
            "original labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 171  = 0.9375\n",
            "loss = 0.12992197275161743\n",
            "\n",
            "\n",
            "step = 171\n",
            "original labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 172  = 1.0\n",
            "loss = 0.025867143645882607\n",
            "\n",
            "\n",
            "step = 172\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 173  = 1.0\n",
            "loss = 0.0004965101834386587\n",
            "\n",
            "\n",
            "step = 173\n",
            "original labels = tensor([1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 174  = 1.0\n",
            "loss = 0.027433864772319794\n",
            "\n",
            "\n",
            "step = 174\n",
            "original labels = tensor([2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 175  = 0.875\n",
            "loss = 0.4086834490299225\n",
            "\n",
            "\n",
            "step = 175\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 176  = 1.0\n",
            "loss = 0.02166464738547802\n",
            "\n",
            "\n",
            "step = 176\n",
            "original labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "Accuracy for batch 177  = 1.0\n",
            "loss = 0.022312309592962265\n",
            "\n",
            "\n",
            "step = 177\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
            "Accuracy for batch 178  = 1.0\n",
            "loss = 0.011509560979902744\n",
            "\n",
            "\n",
            "step = 178\n",
            "original labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "Accuracy for batch 179  = 1.0\n",
            "loss = 0.021491095423698425\n",
            "\n",
            "\n",
            "step = 179\n",
            "original labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 180  = 1.0\n",
            "loss = 0.011023491621017456\n",
            "\n",
            "\n",
            "step = 180\n",
            "original labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 181  = 0.9375\n",
            "loss = 0.19782540202140808\n",
            "\n",
            "\n",
            "step = 181\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 182  = 1.0\n",
            "loss = 0.0015888777561485767\n",
            "\n",
            "\n",
            "step = 182\n",
            "original labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 183  = 1.0\n",
            "loss = 0.00043154912418685853\n",
            "\n",
            "\n",
            "step = 183\n",
            "original labels = tensor([1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2])\n",
            "labels = tensor([1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2])\n",
            "Accuracy for batch 184  = 0.9375\n",
            "loss = 0.27422988414764404\n",
            "\n",
            "\n",
            "step = 184\n",
            "original labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 185  = 1.0\n",
            "loss = 0.011455332860350609\n",
            "\n",
            "\n",
            "step = 185\n",
            "original labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "labels = tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 186  = 1.0\n",
            "loss = 0.02239159494638443\n",
            "\n",
            "\n",
            "step = 186\n",
            "original labels = tensor([2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "labels = tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2])\n",
            "Accuracy for batch 187  = 0.9375\n",
            "loss = 0.1302650272846222\n",
            "\n",
            "\n",
            "step = 187\n",
            "original labels = tensor([2, 2, 2, 2, 1, 2, 1, 2])\n",
            "labels = tensor([2, 2, 2, 2, 1, 2, 1, 2])\n",
            "Accuracy for batch 188  = 1.0\n",
            "loss = 0.04838138073682785\n",
            "\n",
            "\n",
            "Accuracy: 0.97\n",
            "Average Agree Accuracy: 0.63\n",
            "Average Disagree Accuracy: 2.32\n",
            "Average Unrelated Accuracy: 0.07\n",
            "Average validation loss = 0.09424162873681857\n",
            "Validation took: 0:11:30\n"
          ]
        }
      ],
      "source": [
        "## validation ##\n",
        "\n",
        "import torch.nn.functional as F\n",
        "t0 = time.time()\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_agree_accuracy=0\n",
        "total_disagree_accuracy=0\n",
        "total_unrelated_accuracy=0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "total_agree=0\n",
        "total_disagree=0\n",
        "total_unrelated=0\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for step,batch in enumerate(test_dataloader):\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    with torch.no_grad():        \n",
        "\n",
        "        print('step =',step)\n",
        "        output = model(b_input_ids, \n",
        "                                # token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        predictions = F.softmax(output.logits,dim=1)\n",
        "        labels = torch.argmax(predictions,dim=1)\n",
        "        print(\"original labels =\",b_labels )\n",
        "        print(\"labels =\",labels)\n",
        "\n",
        "    acc = validation_accuracy(b_labels, labels)\n",
        "    print(\"Accuracy for batch\",step+1,\" =\",acc[0])\n",
        "    total_eval_accuracy += acc[0]\n",
        "    total_agree_accuracy += acc[1]\n",
        "    total_disagree_accuracy+=acc[2]\n",
        "    total_agree+=acc[3]\n",
        "    total_disagree+=acc[4]\n",
        "    total_unrelated_accuracy+=acc[5]\n",
        "    total_unrelated+=acc[6]\n",
        "\n",
        "    # Accumulate the validation loss.\n",
        "    l=output.loss.item()\n",
        "    print(\"loss =\",l)\n",
        "    total_eval_loss += l\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = output.logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "\n",
        "# Report the final agree accuracy for this validation run.\n",
        "avg_agree_accuracy = total_agree_accuracy / total_agree\n",
        "print(\"Average Agree Accuracy: {0:.2f}\".format(avg_agree_accuracy))\n",
        "\n",
        "# Report the final disagree accuracy for this validation run.\n",
        "avg_disagree_accuracy = total_disagree_accuracy / total_disagree\n",
        "print(\"Average Disagree Accuracy: {0:.2f}\".format(avg_disagree_accuracy))\n",
        "\n",
        "# Report the final unrelated accuracy for this validation run.\n",
        "avg_unrelated_accuracy = total_unrelated_accuracy / total_unrelated\n",
        "print(\"Average Unrelated Accuracy: {0:.2f}\".format(avg_unrelated_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "print(\"Average validation loss =\",avg_val_loss)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "print(\"Validation took: {:}\".format(validation_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "DWLjKUacJuHI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}